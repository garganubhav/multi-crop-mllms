{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "device = 'cuda'\n",
    "model_path = 'Qwen/Qwen2.5-VL-3B-Instruct'\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                attn_implementation=\"eager\",\n",
    "                device_map='auto',\n",
    "            ).eval()\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True, padding_side='left', use_fast=True)\n",
    "\n",
    "image_path = './images/demo1.png'\n",
    "question = 'what is the date of the photo?'\n",
    "\n",
    "messages_query = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image_path,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": f\"{question} Answer:\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "image_inputs, _ = process_vision_info(messages_query)\n",
    "\n",
    "text_query = processor.apply_chat_template(\n",
    "    messages_query,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text_query],\n",
    "    images=image_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "messages_general = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": image_path,\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Write a general description of the image. Answer:\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "text_general = processor.apply_chat_template(\n",
    "    messages_general,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "general_inputs = processor(\n",
    "    text=[text_general],\n",
    "    images=image_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "image_inputs_aux = processor.image_processor(images=image_inputs)\n",
    "output_shape = image_inputs_aux[\"image_grid_thw\"].numpy().squeeze(0)[1:]/2\n",
    "output_shape = output_shape.astype(int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    vision_start_token_id = processor.tokenizer.convert_tokens_to_ids('<|vision_start|>')\n",
    "    vision_end_token_id = processor.tokenizer.convert_tokens_to_ids('<|vision_end|>')    \n",
    "    pos = inputs['input_ids'].tolist()[0].index(vision_start_token_id) + 1\n",
    "    pos_end = inputs['input_ids'].tolist()[0].index(vision_end_token_id)\n",
    "\n",
    "    output = model(**inputs, output_attentions=True)\n",
    "    general_output = model(**general_inputs, output_attentions=True)\n",
    "\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(10.8, 16))\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        att = output.attentions[i][0, :, -1, pos:pos_end].mean(dim=0)\n",
    "        att = att.to(torch.float32).detach().cpu().numpy()\n",
    "\n",
    "        general_att = general_output.attentions[i][0, :, -1, pos:pos_end].mean(dim=0)\n",
    "        general_att = general_att.to(torch.float32).detach().cpu().numpy()\n",
    "\n",
    "        att = att / general_att\n",
    "\n",
    "        ax.imshow(att.reshape(output_shape), cmap='viridis', interpolation='nearest')\n",
    "        ax.set_title(f'Layer {i+1}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()    \n",
    "    plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panda-tmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
